import streamlit as st

def show(proyecto):
    """P√°gina de introducci√≥n"""


    st.markdown("""
    This demo illustrates, through a complete pipeline, the application of the **Research Processes Curation Metamodel (RPCM)** ‚Äî a framework designed to represent the full lifecycle of data-driven projects.
    It covers the entire process, divided into four different steps, from extracting metadata from Kaggle projects to mapping it into RPCM entities for ingestion into Atlas.
    You can find the complete implementation of the pipeline at: 
    """)

    st.markdown(
    """
    <a href="https://colab.research.google.com/drive/17OG-j3m4LR94SWUhnUu40xcyyUfwPIxh?usp=sharing" target="_blank">
        <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
    </a>
    """,
    unsafe_allow_html=True
)

    st.image("assets/pipeline.png")


    # Step 1
    st.markdown("### üîß Step 1: Data Quality Assessment")
    # st.image("assets/step1.svg", caption="Data Quality Assessment")
    st.markdown("""
        Evaluate the reliability of the Kaggle user who created the datasets used in the project, as well as the condition and quality of the data. This includes detection of missing values, duplicates, and other integrity metrics. We implements a cleaning and validation step based on the framework proposed in the paper **The Five Facets of Data Quality Assessment**. 
                
        Applying the five facets to the analysis of Kaggle datasets, we focus primarily on the facets:
                
        - **Source Facet:** Limited by the metadata available through the Kaggle API. We can identify the dataset author and check for source references, but full traceability (e.g., version history, transformation lineage) depends on manual documentation.
        - **Data Facet:** Focusses on structural integrity, data types, missing values, schema consistency, and placeholder values. While accuracy is difficult to validate in the absence of ground-truth benchmarks, the remaining aspects can be assessed in an automated and scalable way.
                
    """)

    # Step 2
    st.markdown("### ‚öôÔ∏è Step 2: Metadata Extraction")
    # st.image("assets/step2.svg", caption="Metadata Extraction")  
    st.markdown("""
        In this step, we will extract metadata from three sources through the Kaggle API:

        - The project notebook.
        - The metadata associated with the project.
        - The outputs generated by the project.

        The metadata obtained will be adapted to a metadata model for Kaggle projects that we modeled, generating a JSON file that consolidates all this information in an organized manner. This will help us make the transformations between models in the next step.
    """)

    # Step 3
    st.markdown("### üîç Step 3: Transformation to RPCM Entities")
    # st.image("assets/step3.svg", caption="Transformation to RPCM Entities")
    st.markdown("""
        When metadata is taken from Kaggle (information about datasets, notebooks, models, and results) it arrives in a raw form. In this step we apply a serie of transformations rules to convert the Kaggle metamodel entities into RPCM entities, ready to be ingested into Apache Atlas. This news entities are connected through unique identifiers, allowing the system to track what was done, who did it, with which data, in which order, and what results were obtained. 
    """)

    # Step 4
    st.markdown("### üìà Step 4: Taxonomy Queries")
    st.markdown("""
        The entities generated in the previous step are imported into Atlas and the content is explored. Once the RPCM entities and instances have been ingested into Apache Atlas, you can explore them through queries.
    """)

    